{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, glob\n",
    "from os.path import join\n",
    "import pypillometry as pp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '4'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '2'\n",
    "import numexpr as ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Define functions for later use\n",
    "##\n",
    "import matplotlib.pyplot\n",
    "# function to apply bandpass filter\n",
    "def bandPass(signal):\n",
    "    fs = 1200.0\n",
    "    lowcut = 0.1\n",
    "    highcut = 40.0\n",
    "\n",
    "    nyq = 0.5*fs\n",
    "    low = lowcut/nyq\n",
    "    high = highcut/nyq\n",
    "\n",
    "    order = 2\n",
    "\n",
    "    b,a = scipy.signal.butter(order, [low, high], 'bandpass', output='ba') # analog=True or analog=False\n",
    "    y = scipy.signal.filtfilt(b, a, signal, axis=-1)\n",
    "    \n",
    "    # trying to keep signal at value location\n",
    "    # zi = scipy.signal.lfilter_zi(b, a); \n",
    "    # y, zo = scipy.signal.lfilter(b, a, signal, zi=zi*signal[0])\n",
    "    # y = scipy.signal.lfilter(b, a, signal, axis=0, zi=None)\n",
    "    \n",
    "    return y\n",
    "\n",
    "# function to load a mat file and store it in pd dataframe\n",
    "def load_mat(matLoc, checkIntPerc = False, data_name = 'Data'):\n",
    "\n",
    "    # vars for voltage correction\n",
    "    maxvolt = 5\n",
    "    minvolt = -5\n",
    "    \n",
    "    mat = scipy.io.loadmat(matLoc)\n",
    "\n",
    "    concat_df = pd.DataFrame(data=[])\n",
    "\n",
    "    interpol_vals = [0]*24\n",
    "    raw_vals = [0]*24\n",
    "    \n",
    "    for b in range(24):\n",
    "        df = pd.DataFrame(data=pd.Series(mat['tskData'][0][0][7][0][b][0]), columns=['time'])\n",
    "        df['pupil'] = mat['tskData'][0][0][6][0][b][3]    \n",
    "        df['block'] = b+1\n",
    "\n",
    "        # interpolate voltages to sizes\n",
    "        df.pupil = (df.pupil-minvolt)/(maxvolt-minvolt)\n",
    "        \n",
    "        # due to continuous values, replace mising data with 0\n",
    "        df['pupil'].mask(df['pupil'] <= 0.01, 0, inplace=True)\n",
    "\n",
    "        # apply bandpass filter\n",
    "        # df.pupil = bandPass(df.pupil)\n",
    "\n",
    "        ## ToDo check for percentage of interpolated data\n",
    "        if checkIntPerc:\n",
    "            # print(b)\n",
    "            int_d, raw_d = int_perc_check(df)\n",
    "            interpol_vals[b] = int_d\n",
    "            raw_vals[b] = raw_d\n",
    "\n",
    "            if ((int_d/raw_d)<=0.3): # see https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6535748/\n",
    "                # concatenate over experimental blocks\n",
    "                concat_df = pd.concat([concat_df, df], ignore_index=True)\n",
    "        else:\n",
    "            concat_df = pd.concat([concat_df, df], ignore_index=True)\n",
    "        \n",
    "    # print(interpol_vals) # print values \n",
    "    \n",
    "    # Pass the x and y cordinates of the bars to the\n",
    "    # function. The label argument gives a label to the data.\n",
    "    calc_data = [0]*24\n",
    "    for i in range(24):\n",
    "        calc_data[i] = interpol_vals[i]/raw_vals[i]\n",
    "\n",
    "    # plot:\n",
    "    matplotlib.pyplot.bar(range(1,25),calc_data, label=data_name)\n",
    "    matplotlib.pyplot.legend()\n",
    "    \n",
    "    # The following commands add labels to our figure.\n",
    "    matplotlib.pyplot.xlabel('Blocks')\n",
    "    matplotlib.pyplot.ylabel('percent')\n",
    "    matplotlib.pyplot.axhline(0.3, color='red')\n",
    "    matplotlib.pyplot.title('Interpolated data in blocks from ' + data_name)\n",
    "    matplotlib.pyplot.savefig(datapath+'pp_dfs/pics_interpolated/'+data_name+'.png', dpi=400)    \n",
    "    matplotlib.pyplot.show()\n",
    "\n",
    "    return concat_df\n",
    "\n",
    "\n",
    "## function to check for percentage of interpolated data (for plotting histogram later)\n",
    "def int_perc_check(pp_data):\n",
    "    data = pp.PupilData(pp_data.pupil, time=pp_data.time, name='test', sampling_rate=1200, fill_time_discontinuities=False)\n",
    "    pp_preprocd = data.blinks_detect(winsize = 150,min_duration=10,strategies=[\"zero\",\"velocity\"],\n",
    "                       vel_onset=-0, vel_offset=0,\n",
    "                       min_onset_len=2, min_offset_len=2)\\\n",
    "                .blinks_merge(distance=100)\\\n",
    "                .blinks_interpolate(winsize=10, margin=(50,150), vel_onset=-0, vel_offset=0)\n",
    "                #.blinks_interp_mahot(winsize=10, margin=(50,150), vel_onset=-0, vel_offset=0) ## currently breaks \n",
    "\n",
    "    n_inter = sum(pp_preprocd.interpolated_mask) # number of interpolated points\n",
    "    n_raw = len(pp_preprocd.sy) # number of raw datapoints\n",
    "    # print(str(n_inter/n_raw)) # print percent of interpolated points\n",
    "    return[n_inter,n_raw]\n",
    "\n",
    "# function to load in multiple datasets\n",
    "def load_PP_data(dataLs, saveBool = True, checkIntPerc = False):\n",
    "\n",
    "    datasets = [None]*len(dataLs)\n",
    "    \n",
    "    for idx,d in enumerate(dataLs):\n",
    "        # load data from mat file\n",
    "        pupil_df = load_mat(datapath+d+'/main/'+'main_eye_'+d+'.mat', checkIntPerc, d)\n",
    "\n",
    "        # load additional behavioural data from csv\n",
    "        behav_df =pd.read_csv(datapath+d+'/main/'+'main_behdf_'+d+'.csv')\n",
    "\n",
    "\n",
    "        if pupil_df.empty != True:\n",
    "            # create pupilData based on combination of pupil and behavioural data\n",
    "            pp_Data = pp.PupilData(pupil_df.pupil, time=pupil_df.time, name=d, sampling_rate=1200, fill_time_discontinuities=False ,event_onsets=behav_df.timing_meg, event_labels=behav_df.block) # standard fill_time_discontinuities=True\n",
    "    \n",
    "        # save PupilData in array\n",
    "        datasets[idx] = pp_Data\n",
    "\n",
    "        # save some ram space\n",
    "        pp_Data = []\n",
    "\n",
    "    if saveBool:\n",
    "        # save pupilData datasets on disk\n",
    "        for ds in datasets:\n",
    "            if ds != []:\n",
    "                fname=os.path.join(datapath+'pp_dfs/', ds.name+\".pd\")\n",
    "                ds.write_file(fname)\n",
    "    \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/Users/scanlab/Documents/internship_luca/pupildata/' # os.getcwd()\n",
    "\n",
    "data2use = ['sub-004', 'sub-005', 'sub-007', 'sub-008', 'sub-009', 'sub-010', 'sub-011']#, 'sub-013', 'sub-014']\n",
    "\n",
    "# load in pupil data and save as pypillometry file on disk\n",
    "load_PP_data(data2use, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/Users/scanlab/Documents/internship_luca/pupildata/pp_dfs/'\n",
    "\n",
    "# load all filenames in `datapath` that end with `.pd`\n",
    "pd_files=[fname for fname in os.listdir(datapath) if fname.endswith(\".pd\")]\n",
    "datasets=[]\n",
    "for fname in pd_files:\n",
    "    fname=os.path.join(datapath, fname)\n",
    "    d=pp.PupilData.from_file(fname)\n",
    "    datasets.append(d)\n",
    "\n",
    "# load all raw datasets\n",
    "exclude=['sub-001','sub-002','sub-012', 'sub-013', 'sub-014'] ## these subject did not have usable data\n",
    "\n",
    "# datasets are stored in a dict structure\n",
    "datasets={d.name.split(\"_\")[0]:d for d in datasets if d.name not in exclude}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify pre-processing parameters per subj\n",
    "default_param={\"min_duration\":10,    # min duration of a blink\n",
    "               \"min_offset_len\":2,   # offset/onset-length for blink-detection\n",
    "               \"min_onset_len\":3,\n",
    "               \"vel_onset\":-0,       # velocity thresholds for onset and offset\n",
    "               \"vel_offset\":0,\n",
    "               \"strategies\":[\"zero\",\"velocity\"],  # strategies for blink-detection\n",
    "              \"distance\":100,        # minimum distance between two blinks\n",
    "              \"margin\":(50,150),     # margins for Mahot algorithm\n",
    "              \"cutoff\":5,            # lowpass-filter cutoff (Hz)\n",
    "              \"downsample\":50}       # downsample to XX Hz\n",
    "\n",
    "# create dict with parameters per subject\n",
    "# all subjects get the same set of default parameters initially\n",
    "params={subj:default_param.copy() for subj in datasets.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fine-tuning of the parameters per subject\n",
    "# subj = \"sub-001\"\n",
    "# No pupil data!\n",
    "# IndexError: index -1 is out of bounds for axis 0 with size 0\n",
    "# subj = \"sub-002\"\n",
    "# No pupil data!\n",
    "# IndexError: index -1 is out of bounds for axis 0 with size 0\n",
    "subj = \"sub-004\"\n",
    "# Writes File\n",
    "subj = \"sub-005\"\n",
    "# Writes File\n",
    "subj = \"sub-007\"\n",
    "# Writes File\n",
    "subj = \"sub-008\"\n",
    "# Writes File\n",
    "subj = \"sub-009\"\n",
    "# Writes File\n",
    "subj = \"sub-010\"\n",
    "# Writes File\n",
    "#params[subj][\"vel_onset\"]=-10\n",
    "subj = \"sub-011\"\n",
    "# Writes File\n",
    "# subj = \"sub-012\"\n",
    "# No pupil data!\n",
    "# IndexError: index -1 is out of bounds for axis 0 with size 0\n",
    "subj = \"sub-013\"\n",
    "# Writes File\n",
    "subj = \"sub-014\"\n",
    "# Writes File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## notes for preprocessing\n",
    "#### subject 4\n",
    "- spike at -2.282\n",
    "- spike at -2.273\n",
    "- spike at -2.266\n",
    "- spike at -2.256\n",
    "- spike at -2.236\n",
    "- spike at -2.225\n",
    "#### subject 5\n",
    "- very noisy\n",
    "- many spikes in beginning & end\n",
    "- data of blocks blur together\n",
    "#### subject 7\n",
    "- clean data with some eyeblinks\n",
    "- interpolated data seems quite good\n",
    "#### subject 8\n",
    "- clean data\n",
    "- not many eyeblinks in the first place\n",
    "- => therefore: some noise in interpolated data might still be existend\n",
    "#### subject 9\n",
    "- overal quite clean data\n",
    "- spike at -2.565\n",
    "- spike at -2.548\n",
    "#### subject 10\n",
    "- clean data, little blinks/artefacts\n",
    "- spike at 0.1525\n",
    "- spike at 0.161\n",
    "- spike at end (0.2)\n",
    "#### subject 11\n",
    "- very clean, little eyeblinks/artefacts\n",
    "- many spikes between 0,27 to 0.28\n",
    "#### subject 13\n",
    "- many eye blinks\n",
    "- start from 0?\n",
    "- no visible spikes\n",
    "#### subject 14\n",
    "- moderate number of eyeblinks\n",
    "- much missing data!\n",
    "- interpolated data makes many \"jumpes\"\n",
    "- very noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run pre-proc pipeline on all subjects and produce PDFs for inspection\n",
    "# add downsampling?\n",
    "preprocs={}\n",
    "# go trough datasets\n",
    "for subj,d in datasets.items():\n",
    "    print(d.name)\n",
    "    pars=params[subj]\n",
    "    # apply predefined parameters\n",
    "    # dp=d.reset_time()\\\n",
    "    dp=d.downsample(400)\\\n",
    "            .blinks_detect(winsize = 150,min_duration=pars[\"min_duration\"],strategies=pars[\"strategies\"],\n",
    "                       vel_onset=pars[\"vel_onset\"], vel_offset=pars[\"vel_offset\"],\n",
    "                       min_onset_len=pars[\"min_onset_len\"], min_offset_len=pars[\"min_offset_len\"])\\\n",
    "            .blinks_merge(distance=pars[\"distance\"])\\\n",
    "            .blinks_interp_mahot(margin=pars[\"margin\"], vel_onset=pars[\"vel_onset\"], vel_offset=pars[\"vel_offset\"])\\\n",
    "            .lowpass_filter(cutoff=pars[\"cutoff\"]).downsample(40)#.reset_time(inplace=True)\n",
    "    # plot preprocessed data and save as pdf or png\n",
    "    # d.reset_time(inplace=True)\n",
    "    plt.figure(figsize=(15,5))\n",
    "    d.plot((d.tx.min(),d.tx.min()+100), units='ms', highlight_blinks=False)\n",
    "    dp.plot((d.tx.min(),d.tx.min()+100), units='ms', highlight_blinks=False)\n",
    "    plt.savefig('/Users/scanlab/Documents/internship_luca/pupildata/pp_dfs/pics/'+subj+'.png')\n",
    "    # d.plot_segments(overlay=dp, pdffile=\"/home/luca/Documents/internship/pupildata/pp_dfs/pics/%s.pdf\"%d.name,figsize=(40,6), ylim=(dp.sy.min(), dp.sy.max()))\n",
    "    # save preprocessed dataset\n",
    "    preprocs[subj]=dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data in individual csv files\n",
    "os.makedirs('/Users/scanlab/Documents/internship_luca/pupildata/pp_dfs/preprocs/', exist_ok=True)  \n",
    "for subj, d in preprocs.items():\n",
    "    if subj not in exclude:\n",
    "        prepro_df =  pd.DataFrame(d.sy, columns = ['pupil'])\n",
    "        prepro_df['time'] =  d.tx\n",
    "        prepro_df.to_csv('/Users/scanlab/Documents/internship_luca/pupildata/pp_dfs/preprocs/40Hz/'+subj+'.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
